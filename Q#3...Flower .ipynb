{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-71daaa6bcb58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandelion=os.listdir('dandelion_reshaped')\n",
    "sunflower=os.listdir('sunflower_reshaped')\n",
    "tulip=os.listdir('tulip_reshaped')\n",
    "rose=os.listdir('rose_reshaped')\n",
    "chamomile=os.listdir('chamomile_reshaped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species=['dandelion','sunflower','tulip','rose','chamomile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store each species of the flower in seperate array named after the species (no need to execute this)\n",
    "print(type(dandelion[0]))\n",
    "count=0\n",
    "\n",
    "\n",
    "dadneliondata=[]\n",
    "for file in dandelion:\n",
    "    temp=cv2.imread(\"dandelion_reshaped/\"+str(file),1)\n",
    "    dadneliondata.append(temp)\n",
    "print(len(dadneliondata))\n",
    "sunflowerdata=[]\n",
    "for file in sunflower:\n",
    "    temp1=cv2.imread(\"sunflower_reshaped/\"+str(file),1)\n",
    "    sunflowerdata.append(temp1)\n",
    "print(len(sunflowerdata))\n",
    "tulipdata=[]\n",
    "for file in tulip:\n",
    "    temp=cv2.imread(\"tulip_reshaped/\"+str(file),1)\n",
    "    tulipdata.append(temp)\n",
    "print(len(tulipdata))\n",
    "rosedata=[]\n",
    "for file in rose:\n",
    "    temp=cv2.imread(\"rose_reshaped/\"+str(file),1)\n",
    "    rosedata.append(temp)\n",
    "print(len(rosedata))\n",
    "chamomiledata=[]\n",
    "for file in chamomile:\n",
    "    temp=cv2.imread(\"chamomile_reshaped/\"+str(file),1)\n",
    "    chamomiledata.append(temp)\n",
    "print(len(chamomiledata))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count=0\n",
    "X=[]\n",
    "for file in dandelion:\n",
    "    temp=cv2.imread(\"dandelion_reshaped/\"+str(file),1)\n",
    "    X.append(temp)\n",
    "print(len(X))\n",
    "for file in sunflower:\n",
    "    temp1=cv2.imread(\"sunflower_reshaped/\"+str(file),1)\n",
    "    X.append(temp1)\n",
    "print(len(X))\n",
    "for file in tulip:\n",
    "    temp=cv2.imread(\"tulip_reshaped/\"+str(file),1)\n",
    "    X.append(temp)\n",
    "print(len(X))\n",
    "for file in rose:\n",
    "    temp=cv2.imread(\"rose_reshaped/\"+str(file),1)\n",
    "    X.append(temp)\n",
    "print(len(X))\n",
    "for file in chamomile:\n",
    "    temp=cv2.imread(\"chamomile_reshaped/\"+str(file),1)\n",
    "    X.append(temp)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to numpy array\n",
    "X=np.array(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output list Y \n",
    "Y=[]\n",
    "for i in range(0,1052):\n",
    "    Y.append(0)\n",
    "for i in range(1052,1781):\n",
    "    Y.append(1)\n",
    "for i in range(1781,2757):\n",
    "    Y.append(2)\n",
    "\n",
    "Y=np.array(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to convert individual list into np array (no need to execute this)\n",
    "dadneliondata=np.array(dadneliondata)\n",
    "sunflowerdata=np.array(sunflowerdata)\n",
    "tulipdata=np.array(tulipdata)\n",
    "rosedata=np.array(rosedata)\n",
    "chamomile=np.array(chamomiledata)\n",
    "\n",
    "\n",
    "\n",
    "print(dadneliondata.shape)\n",
    "print(sunflowerdata.shape)\n",
    "print(tulipdata.shape)\n",
    "print(rosedata.shape)\n",
    "print(chamomile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.6,train_size=0.4, random_state = 0)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "#To find number of classes\n",
    "k=np.unique(Y_train)\n",
    "print(k)\n",
    "K=len(k)\n",
    "print(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(2,2,figsize=(13,13))\n",
    "ax[0,0].imshow(X_train[0])\n",
    "ax[0,0].set_title(str(species[(Y_train[0])]))\n",
    "ax[0,1].imshow(X_train[50])\n",
    "ax[0,1].set_title(str(species[(Y_train[50])]))\n",
    "ax[1,0].imshow(X_train[100])\n",
    "ax[1,0].set_title(str(species[(Y_train[100])]))\n",
    "ax[1,1].imshow(X_train[106])\n",
    "ax[1,1].set_title(str(species[(Y_train[106])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=25\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=Input(shape=X_train[0].shape)\n",
    "X=Conv2D(32,(3,3),strides=(1,1),activation='relu')(i)\n",
    "X=MaxPooling2D(pool_size=(2,2))(X)\n",
    "X=Conv2D(64,(3,3),strides=(1,1),activation='relu')(X)\n",
    "X=MaxPooling2D(pool_size=(2,2))(X)\n",
    "X=Conv2D(96,(3,3),strides=(1,1),activation='relu')(X)\n",
    "X=MaxPooling2D(pool_size=(2,2))(X)\n",
    "X=Conv2D(96,(3,3),strides=(1,1),activation='relu')(X)\n",
    "X=MaxPooling2D(pool_size=(2,2))(X)\n",
    "X=Flatten()(X)\n",
    "X=Dense(512,activation='relu')(X)\n",
    "#X=Dropout(0.2)(X)\n",
    "X=Dense(3,activation='softmax')(X)\n",
    "#X=Dropout(0.2)(X)\n",
    "model=Model(i,X)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "History = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_test,Y_test),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('flowers_model2.h5')\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('flowers_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To resize original image to standard format and saving it\n",
    "img1 = Image.open('predictit.jpg')\n",
    "imResize = img1.resize((150,150), Image.ANTIALIAS)\n",
    "imResize.save('predictit.jpg', 'JPEG', quality=90)\n",
    "predictimg=cv2.imread(\"predictit.jpg\",1)\n",
    "predictimg=np.array(predictimg)\n",
    "plt.imshow(predictimg)\n",
    "predictimg=predictimg/255.0\n",
    "\n",
    "predictimg = np.expand_dims(predictimg, axis=0)\n",
    "predictimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predition=model.predict(predictimg)\n",
    "\n",
    "predition=np.squeeze(predition)\n",
    "print(predition)\n",
    "predIndex=np.argmax(predition)\n",
    "\n",
    "print(\"The Species of given image is\",species[predIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
